{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors against Parallelism\n",
    "\n",
    "* Startup costs associated with initiating (or tearing down) processes\n",
    "  * May often overwhelm actual processing time (rendering ||ism useless)\n",
    "  * Involve thread/process creation, data movement\n",
    "* Interference: slowdown resulting from multiple processors accessing shared resources\n",
    "  * Resources: memory, I/O, system bus, sub-processors\n",
    "  * Software synchronization: locks, latches, mutexes\n",
    "  * Hardware synchronization: cache faults, interrupts\n",
    "* Skew: when breaking a single task into many smaller tasks, not all tasks may be the same size\n",
    "  * Not all tasks finish at the same time\n",
    "  \n",
    "The course will cover all of these in specific details. At this time, you should understand these three factors by visual example. I used to teach this unit by analogy with the real world examples. This was cute, but confusing. I've left this material at the end. The visual examples are boring, but concise and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Startup Costs\n",
    "\n",
    "The NERSC tutorial on OpenMP (our next unit) draws a schematic of a parallel program as consisting of parallel execution parts and serial parts. \n",
    "\n",
    "<img src=\"https://docs.nersc.gov/development/programming-models/openmp/OpenMPforkjoin.png\" width=\"500\" title=\"https://docs.nersc.gov/development/programming-models/openmp/OpenMPforkjoin.png\" />\n",
    "\n",
    "The portions of the progam in the parallel region during which the threads are not running fully in parallel are the startup costs (or teardown costs). The dashed lines indicate periods of time in which the program is not running in parallel. The solid lines indicate times when the program is running in parallel.\n",
    "\n",
    "During the sequential parts, one would not expect parallelism. This diagram shows that even during the parallel parts, one might not realize perfect parallelism.\n",
    "\n",
    "Examples of startup costs include:\n",
    "  * operating system overheads: creation of threads of processes\n",
    "  * data access: loading or copying data to the parallel workers\n",
    "  \n",
    "Similarly we may experience teardown costs in closing parallel contexts:\n",
    "  * operating system cleaning up thread/process state\n",
    "  * copying partial results from parallel computation to memory or storage\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interference\n",
    "\n",
    "The paper [Thiffault et al. Dynamic instrumentation of large-scale MPI and OpenMP applications](http://cs.umanitoba.ca/pub/IPDPS03/DATA/16_04_089.PDF) shows a timeline of parallel computation of a neutron-transfer physics code. The image shows multiple processes awaiting on data to be transferred from other nodes and threads within each process executing intermittently.   \n",
    "\n",
    "<img src=\"./images/sweep3d.png\" width=\"500\" /> \n",
    "\n",
    "Interference arises when parallel execution contexts have to wait on each other. This manifests in multiple ways:\n",
    "  * communicating processes waiting on messages\n",
    "  * processes waiting on shared resources\n",
    "      * these can be sofware constructs, such as locks\n",
    "      * or they can be hardware constructs, such as cache lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew\n",
    "\n",
    "Skew arises when execution cannot advance until all jobs complete. This problem is most acute when one decomposes a problem into independent parts that are of different sizes. The following chart from [Uselton et al. Parallel I/O Performance: From Events to Ensembles](https://crd.lbl.gov/assets/pubs_presos/CDS/FTG/Papers/2010/ipdps10ipm.pdf) shows a parallel code that is running particularly poorly owing to long-running processes.\n",
    "\n",
    "<img src=\"./images/ioensembles.png\" width=\"500\" />\n",
    "\n",
    "This is an I/O trace. The blue and red lines indicate periods when I/O is being conducted and the white space indicates all else. In this code, all I/O must complete prior to a barrier prior to the computation continuing. The chart shows processes completing waiting for the long running processes. \n",
    "\n",
    "Long running processes are called. \"stragglers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Factors\n",
    "\n",
    "Many computational frameworks operate in a manner in which they:\n",
    "  * launch a bunch of parallel jobs (startup)\n",
    "  * wait for all jobs to complete (skew)\n",
    "  * integrate/coordinate the parts (interference)\n",
    "  * restart a bunch of new parallel jobs -- REPEAT!\n",
    "  \n",
    "  \n",
    "The following diagram of the bulk synchronous computing model shows skew and synchronization. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Bsp.wiki.fig1.svg/540px-Bsp.wiki.fig1.svg.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Computers: Real things that Degrade Parllelism\n",
    "\n",
    "* I/O (memory and storage)\n",
    "  * may be startup (load data before computation)\n",
    "  * may be interference (awaiting data transfer between parallel tasks)\n",
    "  * may be skew (await I/O completion of one task)\n",
    "* Network communication\n",
    "    * similar to I/O but always involves communication\n",
    "* Failuresâ€”particularly slow/failed processes (often skew)\n",
    "\n",
    "The HPC community focuses on communication (among processes) as the major source of slowdown.  This is a traditional (I/O and networking) view.\n",
    "\n",
    "### Communication\n",
    "\n",
    "* Parallel computation proceeds in phases\n",
    "  * Compute (evaluate data that you have locally)\n",
    "* Communicate (exchange data among compute tasks).  Performance is governed by:\n",
    "  * Latency: fixed cost to send a message\n",
    "  * Round trip time (speed of light and switching costs)\n",
    "* Bandwidth: marginal cost to send a message\n",
    "  * Link capacity\n",
    "* Latency dominates small messages and bandwidth dominates large.\n",
    "  * It is lmost always better to increase message size for performance, but difficult to achieve in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation: Overlapped I/O and Computation\n",
    "\n",
    "(I/O or messaging) and computation that occur in parallel are overlapped\n",
    "\n",
    "<img src=\"./images/overlap.png\" width=\"512\" title=\"Unknown source\" />\n",
    "\n",
    "* _Concept_: When performing a slow operation\n",
    "  * do the slow operation asynchronously\n",
    "  * do useful work with processor while waiting\n",
    "* Overlap is one of the simplest and most important forms of asynchronous execution\n",
    "  * identify independent tasks and do in parallel\n",
    "  * reorder I/O to initiate as early as possible and wait as late as possible\n",
    "  * while computing at the same time\n",
    "  \n",
    "I've built a toy example to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute \n",
    "def factorial(number):  \n",
    "    f = 1\n",
    "    for i in range(2, number+1):\n",
    "        f *= i\n",
    "    return f\n",
    " \n",
    "# synchronous I/O\n",
    "def io_from_devnull(number):\n",
    "    with open(\"/dev/null\", \"rb\") as fh:\n",
    "        for i in range(number):\n",
    "            fh.read(1)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit factorial(10000)\n",
    "%timeit io_from_devnull(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 \n",
    "factorial(10000)\n",
    "io_from_devnull(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paralleldefs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sz/0by7h1yx3v5cf1r2bdld98c40000gn/T/ipykernel_61910/3662468443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nfrom multiprocessing import Process\\np1 = Process(target=paralleldefs.factorial, args=(10000,))\\np2 = Process(target=paralleldefs.io_from_devnull, args=(30000,))\\np1.start()\\np2.start() \\np1.join()\\np2.join()\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paralleldefs' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit -n 20\n",
    "\n",
    "from multiprocessing import Process\n",
    "p1 = Process(target=paralleldefs.factorial, args=(10000,))\n",
    "p2 = Process(target=paralleldefs.io_from_devnull, args=(30000,))\n",
    "p1.start()\n",
    "p2.start() \n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors Conclusions\n",
    "\n",
    "* Factors against parallelism are the most important design consideration.\n",
    "* Considered in light of Amdahl's law\n",
    "    * when we estimate an Amdahl number from empirical results all factors contribute to the unoptimized portion\n",
    "    * when we implement a parallel portion from an instrumented serial version, the factors are why the realized speedup is less than the ideal speedup\n",
    "* Performance visualization tools are a valuable part of understanding and debugging parallelism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
